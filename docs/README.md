# Nomous Local Autonomy Runtime

This document provides a runtime-centric view of how Nomous stitches together the Python workers and the React dashboard.

## System Components
- **WebSocket bridge** orchestrates messages between the UI and backend subsystems.ã€F:scripts/run_bridge.pyâ€ L1-L213ã€‘
- **Local LLM (`llama.cpp`)** streams tokens, surfaces thought events, and can reload models at runtime.ã€F:src/backend/llm.pyâ€ L21-L212ã€‘
- **Speech input** converts PCM16 microphone data into transcripts using Vosk and automatically triggers LLM turns.ã€F:src/backend/audio.pyâ€ L33-L118ã€‘
- **Piper TTS** synthesises audio and (on Windows) triggers local playback, with toggles exposed through WebSocket parameters.ã€F:src/backend/tts.pyâ€ L29-L138ã€‘ã€F:scripts/run_bridge.pyâ€ L72-L157ã€‘
- **Camera & vision loop** streams preview frames, detects motion/gestures, and prompts the LLM for descriptions.ã€F:src/backend/video.pyâ€ L28-L123ã€‘ã€F:src/backend/video.pyâ€ L360-L437ã€‘
- **Memory store** persists interactions to SQLite and rebroadcasts the graph to the dashboard for analytics.ã€F:src/backend/memory.pyâ€ L13-L167ã€‘
- **System monitor** pushes CPU/GPU telemetry so the UI can display device health in real time.ã€F:src/backend/system.pyâ€ L1-L152ã€‘

## Feature Status Overview
### âœ… Complete
- Tool execution framework with nine built-in tools and UI activity feed.ã€F:src/backend/tools.pyâ€ L32-L187ã€‘ã€F:src/frontend/components/ToolActivity.tsxâ€ L6-L213ã€‘
- Gesture-aware camera loop with MediaPipe integration and vision cooldown controls.ã€F:src/backend/video.pyâ€ L28-L123ã€‘ã€F:src/backend/video.pyâ€ L360-L437ã€‘
- Load-progress overlay for LLM initialisation and model reloads.ã€F:src/backend/llm.pyâ€ L65-L115ã€‘ã€F:src/frontend/App.tsxâ€ L330-L383ã€‘
- Behaviour metrics, token throughput charts, and reward accounting surfaced in the dashboard.ã€F:src/backend/handlers.pyâ€ L24-L43ã€‘ã€F:src/frontend/App.tsxâ€ L1614-L2158ã€‘

### âš ï¸ WIP / Limited
- Piper auto-playback still depends on Windows PowerShell â€“ replace `_play_audio` for cross-platform support.ã€F:src/backend/tts.pyâ€ L87-L123ã€‘
- GPU telemetry requires `torch`, `pynvml`, and `psutil`; missing dependencies disable metrics and break `tests/test_system.py` during import.ã€F:src/backend/system.pyâ€ L1-L152ã€‘ã€F:tests/test_system.pyâ€ L1-L120ã€‘
- Pytest async markers emit warnings until `pytest.ini` declares `asyncio` as a known mark.ã€F:tests/test_tools.pyâ€ L80-L328ã€‘

### ğŸš§ Not Implemented Yet
- Additional gesture classes and wake-word activation remain roadmap items from the changelog.ã€F:docs/CHANGELOG.mdâ€ L136-L170ã€‘
- Cross-platform Piper playback so the spoken responses work on Linux/macOS.ã€F:src/backend/tts.pyâ€ L87-L123ã€‘

## Repository Layout
```
nomous/
â”œâ”€ scripts/
â”‚  â”œâ”€ start.py          # Launch backend + React dev server
â”‚  â””â”€ run_bridge.py     # Standalone backend runtime
â”œâ”€ src/
â”‚  â”œâ”€ backend/          # Python workers (LLM, STT, TTS, vision, memory)
â”‚  â””â”€ frontend/         # React dashboard (tabs, charts, controls)
â””â”€ docs/                # Guides, changelog, implementation notes
```

## Key Configuration Fields
```yaml
paths:
  gguf_path: /path/to/model.gguf
  vosk_model_dir: /path/to/vosk-model
  piper_exe: /path/to/piper.exe
  piper_voice: /path/to/voice.onnx
  piper_out_dir: /path/to/output-dir

llm:
  n_ctx: 2048
  n_threads: 4
  temperature: 0.6
  top_p: 0.95
  tools_enabled: true

audio:
  sample_rate: 16000
  sensitivity: 60

camera:
  backend: dshow
  index: 0
  width: 1280
  height: 720
  process_width: 640
  process_height: 360
  frame_skip: 2

ui:
  snapshot_debounce: 4
  motion_sensitivity: 30
  vision_enabled: true
  gesture_enabled: true
  vision_cooldown: 12
  gesture_cooldown: 3
  tts_enabled: true

memory:
  enable: true
  db_path: ./data/memory/nomous.sqlite
```

### Optional Integrations
- Set `llm.n_gpu_layers` and install CUDA-enabled `llama-cpp-python` for GPU offload.ã€F:src/backend/llm.pyâ€ L89-L115ã€‘
- Install `mediapipe` to enable gesture recognition inside the camera loop.ã€F:src/backend/video.pyâ€ L37-L64ã€‘
- Provide a valid Piper voice/executable pair to enable text-to-speech in addition to subtitles.ã€F:src/backend/tts.pyâ€ L29-L138ã€‘
